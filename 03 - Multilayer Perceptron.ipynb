{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a multilayer perceptron (MLP) to recognize handwritten digits using the MNIST dataset. An MLP is the simplest type of artificial neural network.\n",
    "\n",
    "We begin by importing the functions and modules that we will use in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidradcliffe/anaconda/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is included in scikit-learn, so we don't need to download it. The dataset has already been split into a training set and a test set. There are 60000 images in the training set, and 10000 images in the test set.\n",
    "\n",
    "Each image is a 28 by 28 array of integers between 0 and 255. 0 represents no ink (white) and 255 represents ink (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d9cc5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"This is a %d.\" % y_train[0])\n",
    "_ = plt.imshow(X_train[0], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is unrolled into a 1-dimensional array, and the values are rescaled from 0 to 1, instead of 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784) / 255\n",
    "X_test = X_test.reshape(-1, 784) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels (y-values) must be one-hot encoded. This means that each value 0-9 is encoded as a vector of length 10 in the following manner:\n",
    "\n",
    "    0 = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    1 = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    2 = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    3 = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "    4 = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "    5 = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "    6 = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "    7 = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "    8 = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "    9 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a neural network. It has one dense hidden layer with 128 nodes. Since we have a classification task with 10 classes, the final layer has 10 nodes and uses the softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, the softmax function converts the outputs into probabilities, by producing 10 positive numbers that add up to 1. Larger numbers result in higher probabilities. We could code the softmax function ourselves, although it is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03168492 0.63640865 0.08612854 0.01165623 0.23412166]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax(vector):\n",
    "    return np.exp(vector) / np.sum(np.exp(vector))\n",
    "\n",
    "probabilities = softmax([-1, 2, 0, -2, 1])\n",
    "print(probabilities)\n",
    "print(probabilities.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model for 10 epochs, we obtain nearly 98% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.2596 - acc: 0.9265\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.1208 - acc: 0.9645\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0891 - acc: 0.9740\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0732 - acc: 0.9787 0s - loss: 0.0735 - acc: 0.97\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0616 - acc: 0.9826\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0522 - acc: 0.9855\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0453 - acc: 0.9872\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0402 - acc: 0.9886\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0360 - acc: 0.9902\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0313 - acc: 0.9917\n",
      "10000/10000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1068077201799566, 0.9768]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the model predictions. Recall that our model is estimating a probability for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0256632e-16, 1.6521894e-16, 9.2894907e-11, ..., 9.9999988e-01,\n",
       "        4.2331904e-13, 6.1810806e-11],\n",
       "       [2.4392708e-18, 4.7543119e-14, 1.0000000e+00, ..., 8.1715981e-33,\n",
       "        4.0044711e-18, 1.0254833e-33],\n",
       "       [1.2380830e-12, 9.9943060e-01, 1.4092071e-05, ..., 4.1045263e-05,\n",
       "        5.0922442e-04, 1.4505965e-09],\n",
       "       ...,\n",
       "       [6.9089408e-20, 5.0719401e-19, 8.8687224e-19, ..., 5.6925909e-08,\n",
       "        1.0877205e-09, 4.2968336e-06],\n",
       "       [4.3987995e-21, 5.5042518e-22, 7.6265166e-23, ..., 1.4237147e-19,\n",
       "        2.5527583e-10, 2.6023491e-20],\n",
       "       [1.8795938e-19, 1.6873140e-34, 7.4878102e-20, ..., 3.1443166e-28,\n",
       "        6.5368898e-28, 9.6912154e-25]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we really want is the most probable class for each observation, not the class probabilities. We use the `argmax` method to tell us the index, in each row, where maximum probability occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test.argmax(axis=1)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "print(y_pred[:20])\n",
    "print(y_true[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the confusion matrix. Which digits are most often confused with each other? Are these mistakes surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1127</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>977</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>876</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>932</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4    5    6    7    8    9\n",
       "0  970     0     1    1    1    1    3    1    1    1\n",
       "1    0  1127     3    0    0    3    2    0    0    0\n",
       "2    4     2  1001    3    2    1    3    9    7    0\n",
       "3    0     0     8  977    0   12    0    3    0   10\n",
       "4    0     0     3    1  964    0    3    1    0   10\n",
       "5    2     0     0    5    1  876    4    0    2    2\n",
       "6    4     2     0    1    4    9  938    0    0    0\n",
       "7    2     4     7    4    0    0    0  995    4   12\n",
       "8    6     0     3    6    5   11    3    2  932    6\n",
       "9    1     2     0    2    9    4    0    2    1  988"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_true, y_pred), index=range(10), columns=range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
